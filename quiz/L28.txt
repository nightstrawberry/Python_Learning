对于第二个问题，答案是：目前谷歌翻译所支持的一部分语言对需要以第三种语言作为中介，一部分语言对则不需要。毕竟开发有先后，资源也有限，不能指望每个语言对的翻译所使用的技术完全一样，除非哪天我们做了个大统一模型……

以第三种语言为中介算是一个折中的选择。除了训练数据不那么好准备之外，这么多模型所需要的资源也是必须考虑的问题。比方说，如果现在要支持一百种语言的直接互译，那就得同时运行和维护一万个模型。而如果只开发英语相关的模型，其他非英语的语言对翻译全部通过英语作为中介，那么需要运行和维护的模型数量就降到了两百。

当然，通过中介语言进行翻译的一个显而易见的问题在于翻译的错误是会累积的（其他回答中已经吐槽得很到位了，虽然不一定是因为使用了中介语言的锅……）。就好比一句话被好几个人传过之后，意思可能会跟原本的差了十万八千里。在这个问题上，除了开发新模型来做直接翻译之外，还有许多其他解决方案。

比如说 GNMT 支持多语言训练，也可以进行 Zero-Shot 学习（https://arxiv.org/abs/1611.04558）。简单来讲就是可以喂给模型各种语言对的训练数据，然后用这一个模型进行多种语言对的翻译。听上去是不是很神（bao）奇（li）！再比如说新出的 Transformer 模型（https://arxiv.org/abs/1706.03762）直接舍弃 RNN，纯用 Attention 来刻画句子特征，从而提升可并行性。

总之，技术在不断进步，希望这个问题也能常看常新，而谷歌翻译能越做越贴心。